---
title: "discriminating-words"
author: "Rochelle Terman"
date: "June 24, 2015"
output: html_document
---

### Required Packages

```{r}
setwd("~/Dropbox/berkeley/Dissertation/Data and Analyais/Git Repos/text-analysis-dhbsi")
rm(list=ls())
library(tm)
library(RTextTools) # a machine learning package for text classification written in R
library(SnowballC) # for stemming
library(matrixStats) # for statistics
```


## 0. Prepare
```{r}
docs <- Corpus(DirSource("Data/British_Fiction/Selection"))
docs
dtm <- DocumentTermMatrix(docs,
           control = list(stopwords = T,
                          tolower = TRUE,
                          removeNumbers = TRUE,
                          removePunctuation = TRUE,
                          stemming=TRUE))
dim(dtm)
inspect(dtm[,100:104])
```

## Measuring “distinctiveness”
Finding distinctive words requires a decision about what “distinctive” means. As we will see, there are a variety of definitions that we might use. It seems reasonable to expect that all definitions of distinctive would identify as distinctive words found exclusively in texts associated with a single author (or group). For example, if Brontë uses the word “access” and Austen never does, we should count “access” as distinctive. 

Finding words that are unique to a group is a simple exercise. Indeed, it is worth treating these words a special case so they will not clutter our work later on. We will quickly identify these words and remove them. (They tend not to be terribly interesting words.)

A simple way of identifying words unique to one author would be to calculate the average rate of word use across all texts for each author and then to look for cases where the average rate is zero for one author.

```{r}
# turn into dataframe
dtm.m <- as.data.frame(as.matrix(dtm))
dtm.m[,1:5]

# Subset into 2 dtms
austen <- dtm.m[1:3,]
bronte <- dtm.m[4:6,]

# add the values in each columns
austen <- colSums(austen)
bronte <- colSums(bronte)

# put it back into a dataframe
df <- data.frame(rbind(austen,bronte))
df[,1:5]

# get words where one author's proportion is 0
solelyAusten <- unlist(df[1,bronte==0])
solelyAusten <- solelyAusten[order(solelyAusten, decreasing = T)]
solelyAusten[1:10]

solelyBronte <- unlist(df[2,austen==0])
solelyBronte <- solelyBronte[order(solelyBronte, decreasing = T)]
solelyBronte[1:10]
```

We Now that we have identified these words, we will remove them from our corpus in order to focus on identifying distinctive words that appear in texts associated with every author.

```{r}
# subset df with non-zero entries
df <- df[,bronte>0 & austen>0]
# how many words are we left with?
ncol(df)
df[,1:5]

# normalize into proportions
rowTotals <- rowSums(df) #create column with row totals, total number of words per document
head(rowTotals)
df <- df/rowTotals #change frequencies to proportions
df[,1:5] # how we have proportions.

# get difference in proportions
means.austen <- df[1,]
means.bronte <- df[2,]

score <- unlist(means.austen - means.bronte)
score <- sort(score)
head(score,10) # top session words
tail(score,10) # top austen words
```

This is a start. The problem with this measure is that it tends to highlight differences in very frequent words. For example, this method gives greater attention to a word that occurs 30 times per 1,000 words in Austen and 25 times per 1,000 in Brontë than it does to a word that occurs 5 times per 1,000 words in Austen and 0.1 times per 1,000 words in Brontë. This does not seem right. It seems important to recognize cases when one author uses a word frequently and another author barely uses it.

As this initial attempt suggests, identifying distinctive words will be a balancing act. When comparing two groups of texts differences in the rates of frequent words will tend to be large relative to differences in the rates of rarer words. Human language is variable; some words occur more frequently than others regardless of who is writing. We need to find a way of adjusting our definition of distinctive in light of this.

```{r]}

means.all <- colMeans(df)

score <- unlist((means.austen - means.bronte) / means.all)
score <- sort(score)
head(score,10) # top session words
tail(score,10) # top austen words
```

A more nuanced comparison of word use in two groups takes account of the variability in word use. Consider for instance the word “green” in Austen and Brontë. In Austen the word occurs with the following rates: 0.01, 0.03, and 0.06 (0.03 on average). In Brontë the word is consistently more frequent: 0.16, 0.36, and 0.22 (0.24 on average). These two groups of rates look different. But consider how our judgment might change if the rates observed in Brontë’s novels were much more variable, say, 0.03, 0.04, and 0.66 (0.24 on average). Although the averages remain the same, the difference does not seem so pronounced; with only one observation (0.66) noticeably greater than we find in Austen, we might reasonably doubt that there is evidence of a systematic difference between the authors.

The following metric takes variation into account.

```{r}
# start again with turning original rate dtm into dataframe
dtm.m <- as.data.frame(as.matrix(dtm))
dtm.m[,1:5]

# Subset into 2 dtms
austen <- dtm.m[1:3,]
bronte <- dtm.m[4:6,]

# calculate means and vars
means.austen <- colMeans(austen)
var.austen <- colVars(as.matrix(austen))
means.bronte <- colMeans(bronte)
var.bronte <- colVars(as.matrix(bronte))
  
#calculate overall score
num <- (means.austen - means.bronte) 
denom <- sqrt((var.austen/3) + (var.bronte/3))
score <- num / denom

# remove -inf and -inf
score <- score[-which(score=="-Inf")]
score <- score[-which(score=="Inf")]

# sort and view
score <- sort(score)
head(score,10) # top bronte words
tail(score,10) # top austen words
```

Yet another metric is "standard log odds", used in Monroe, Colaresi, and Quinn (2009)

```{r}
# calculate means and vars
n.austen <- sum(colSums(austen))
n.bronte <- sum(colSums(bronte))

pi.austen <- (colSums(austen) + 1) / (n.austen+ ncol(austen)-1)
pi.bronte <- (colSums(bronte) + 1) / (n.bronte + ncol(bronte)-1)  

log.odds.ratio <- log(pi.austen/(1-pi.austen)) - log(pi.bronte / (1-pi.bronte))
st.log.odds <- log.odds.ratio/sqrt(var(log.odds.ratio))

st.log.odds <- sort(st.log.odds)
head(st.log.odds,10) # top bronte words
tail(st.log.odds,10) # top austen words
